{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP Victus 16\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyfolio\\pos.py:26: UserWarning: Module \"zipline.assets\" not found; mutltipliers will not be applied to position notionals.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import empyrical as ep\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "import pyfolio as pf\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "\n",
    "import datetime\n",
    "import warnings\n",
    "import pytz\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable future warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tickers\n",
    "\n",
    "tickers = {\n",
    "    \"^GSPC\": \"S&P 500\",\n",
    "    \"^DJI\": \"Dow Jones Industrial Average\",\n",
    "    \"^IXIC\": \"NASDAQ Composite\",\n",
    "    \"^NYA\": \"NYSE COMPOSITE (DJ)\",\n",
    "    \"^XAX\": \"NYSE AMEX COMPOSITE INDEX\",\n",
    "    \"^BUK100P\": \"Cboe UK 100\",\n",
    "    \"^RUT\": \"Russell 2000\",\n",
    "    \"^FTSE\": \"FTSE 100\",\n",
    "    \"^GDAXI\": \"DAX PERFORMANCE-INDEX\",\n",
    "    \"^FCHI\": \"CAC 40\",\n",
    "    \"^STOXX50E\": \"ESTX 50 PR.EUR\",\n",
    "    \"^N100\": \"Euronext 100 Index\",\n",
    "    \"^BFX\": \"BEL 20\",\n",
    "    \"IMOEX.ME\": \"MOEX Russia Index\",\n",
    "    \"^N225\": \"Nikkei 225\",\n",
    "    \"^HSI\": \"HANG SENG INDEX\",\n",
    "    \"000001.SS\": \"SSE Composite Index\",\n",
    "    \"399001.SZ\": \"Shenzhen Index\",\n",
    "    \"^STI\": \"STI Index\",\n",
    "    \"^AXJO\": \"S&P/ASX 200\",\n",
    "    \"^AORD\": \"ALL ORDINARIES\",\n",
    "    \"^BSESN\": \"S&P BSE SENSEX\",\n",
    "    \"^JKSE\": \"IDX COMPOSITE\",\n",
    "    \"^KLSE\": \"FTSE Bursa Malaysia KLCI\",\n",
    "    \"^NZ50\": \"S&P/NZX 50 INDEX GROSS (GROSS)\",\n",
    "    \"^KS11\": \"KOSPI Composite Index\",\n",
    "    \"^TWII\": \"TSEC weighted index\",\n",
    "    \"^GSPTSE\": \"S&P/TSX Composite index\",\n",
    "    \"^BVSP\": \"IBOVESPA\",\n",
    "    \"^MXX\": \"IPC MEXICO\",\n",
    "    \"^MERV\": \"MERVAL\",\n",
    "    \"^TA125.TA\": \"TA-125\",\n",
    "    \"^JN0U.JO\": \"Top 40 USD Net TRI Index\",\n",
    "    \"^SET.BK\": \"Stock Exchange of Thailand\",\n",
    "    \"TDEX.BK\": \"ThaiDEX SET50\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch data for a ticker\n",
    "def fetch_data(ticker, start_date, end_date):\n",
    "    dft = yf.Ticker(ticker)\n",
    "    df = dft.history(interval=\"1d\", start=start_date, end=end_date)\n",
    "    df['Ticker'] = ticker\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tickers_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 20\u001b[0m\n\u001b[0;32m     16\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Loop through each ticker\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ticker \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtickers_list\u001b[49m:\n\u001b[0;32m     23\u001b[0m     df \u001b[38;5;241m=\u001b[39m fetch_data(ticker, startDate, endDate)\n\u001b[0;32m     24\u001b[0m     dft \u001b[38;5;241m=\u001b[39m yf\u001b[38;5;241m.\u001b[39mTicker(ticker)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tickers_list' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the start and end dates for the data\n",
    "startDate = \"1990-01-01\"\n",
    "endDate = \"2024-01-01\"\n",
    "\n",
    "# Create an empty DataFrame to store all data\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "# tickers_list = [\"^SET.BK\", \"AWC.BK\"]\n",
    "\n",
    "showModelScores = False\n",
    "\n",
    "gridSearch = False\n",
    "\n",
    "cvTest = False\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "\n",
    "# Loop through each ticker\n",
    "for ticker in tickers_list:\n",
    "    \n",
    "    \n",
    "    df = fetch_data(ticker, startDate, endDate)\n",
    "    dft = yf.Ticker(ticker)\n",
    "    timeZone = dft.info.get(\"timeZoneFullName\")\n",
    "    tickerName = dft.info.get(\"longName\", \"Unknown Ticker\")\n",
    "    \n",
    "    print(f\"{ticker} : ({tickerName})\")\n",
    "    \n",
    "    # df\n",
    "    \n",
    "    # Drop columns\n",
    "    df.drop(columns=['Dividends'], inplace=True)\n",
    "    # Drop Stock Splits column\n",
    "    df.drop(columns=['Stock Splits'], inplace=True)\n",
    "\n",
    "    ## Calculate EMA-12 and EMA-26 using Exponential Weighing Average (EWM)\n",
    "    # df['EMA-12'] = df['Close'].ewm(span = 12, adjust = False).mean()\n",
    "    # df['EMA-26'] = df['Close'].ewm(span = 26, adjust = False).mean()\n",
    "\n",
    "    ## Calculate MACD \n",
    "    # df['MACD'] = df['EMA-12'] - df['EMA-26']\n",
    "    df['MACD'] = ta.macd(df['Close'], fast=12, slow=26, signal=9)['MACD_12_26_9']\n",
    "    df['Pct_Change'] = df['Close'].pct_change() * 100\n",
    "\n",
    "    ## Calculate RSI using formula\n",
    "    ## RSI = 100 – [100 ÷ ( 1 + (Average Gain During Up Periods ÷ Average Loss During Down Periods ))]\n",
    "\n",
    "    delta = df['Close'].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "    rs = gain / loss\n",
    "    df['RSI'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "    delta = df['Close'].diff()\n",
    "    gain = delta.where(delta > 0, 0)\n",
    "    loss = -delta.where(delta < 0, 0)\n",
    "\n",
    "    # Calculate the Exponential Moving Average of gains and losses\n",
    "    avg_gain = gain.ewm(span=14, min_periods=14).mean()\n",
    "    avg_loss = loss.ewm(span=14, min_periods=14).mean()\n",
    "\n",
    "    # Calculate the RS and RSI\n",
    "    rs = avg_gain / avg_loss\n",
    "    df['RSI_EMA'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "    df['RSI_ta'] = ta.rsi(df['Close'], length=14)\n",
    "\n",
    "    df['MA10'] = df.ta.sma(length=10)\n",
    "    df['MA50'] = df.ta.sma(length=50)\n",
    "    df['MA200'] = df.ta.sma(length=200)\n",
    "\n",
    "    ## Calculate Boilinger Bands\n",
    "    window = 20\n",
    "    df['MA20'] = df['Close'].rolling(window=window).mean()\n",
    "    df['std_dev'] = df['Close'].rolling(window=window).std()\n",
    "    df['Upper_BB'] = df['MA20'] + (df['std_dev'] * 2)\n",
    "    df['Lower_BB'] = df['MA20'] - (df['std_dev'] * 2)\n",
    "    \n",
    "    # Create target variable: 1 if next day's close is higher than today's, else 0\n",
    "    df['Target'] = (df['Close'].shift(-1) > df['Close']).astype(int)\n",
    "    \n",
    "    \n",
    "    vix = yf.Ticker(\"^VIX\")\n",
    "    vix_df = vix.history(interval=\"1d\", start=startDate, end=endDate)\n",
    "\n",
    "    vix_df['Pct_Change'] = vix_df['Close'].pct_change() * 100\n",
    "\n",
    "    # print(vix_df['Pct_Change'].max())\n",
    "\n",
    "    # Get the time zone of the stock's exchange\n",
    "    stock_timezone = pytz.timezone(timeZone)\n",
    "\n",
    "    # Convert the time zone of the VIX DataFrame to match the time zone of the stock's exchange\n",
    "    vix_df.index = vix_df.index.tz_convert(stock_timezone)\n",
    "\n",
    "    # Align the timestamps of the VIX data to match those of your DataFrame\n",
    "    vix_df = vix_df.reindex(df.index, method='ffill')\n",
    "\n",
    "    vix_df['AVG'] = ( vix_df['Open'] + vix_df['High'] + vix_df['Low'] + vix_df['Close'] ) / 4\n",
    "    # Merge VIX close prices into the original DataFrame\n",
    "    df['VIX'] = vix_df['Close']\n",
    "   \n",
    "    df = df.dropna()\n",
    "        \n",
    "    # Prepare the feature set and target variable\n",
    "    X = df[['Pct_Change', 'std_dev', 'MA200', 'MA50', 'MA10', 'MACD', 'RSI_ta', 'VIX']]\n",
    "    # X = df[['MA200', 'MA50', 'MA10', 'MACD2', 'RSI_ta', 'VIX', 'VIX_35', 'VIX_65']]\n",
    "    # X = df[['SMA200', 'SMA50', 'SMA10', 'MACD', 'RSI', 'VIX', 'VIX_35', 'VIX_65', 'MA20', 'Lower_BB', 'Upper_BB']]\n",
    "    y = df['Target']\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "    # Train the RandomForestClassifier\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=100, \n",
    "        random_state=42, \n",
    "        max_depth=5, \n",
    "        min_samples_leaf=1, \n",
    "        min_samples_split=10\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    if showModelScores:\n",
    "        print(\"Model 1 : Train score : \", model.score(X_train,y_train))\n",
    "        print(\"Model 1 : Test score : \", model.score(X_test,y_test))\n",
    "        \n",
    "    if cvTest:\n",
    "        cv_scores = cross_val_score(model, X, y, cv=5)\n",
    "    \n",
    "    if showModelScores:\n",
    "        print(\"Model 1 : Cross-validation scores:\", cv_scores)\n",
    "        print(\"Model 1 : Mean cross-validation score:\", cv_scores.mean())\n",
    "\n",
    "    # Define hyperparameters grid for Random Forest\n",
    "    rf_param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [5, 10, 15],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "\n",
    "    # Define hyperparameters grid for XGBoost\n",
    "    xgb_param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.1, 0.01, 0.001, 0.005, 0.0025, 0.00125],\n",
    "        'subsample': [0.8, 0.9],\n",
    "        'colsample_bytree': [0.8, 0.9],\n",
    "        'gamma': [0.1, 0.2],\n",
    "        'reg_alpha': [0.1, 0.2],\n",
    "        'reg_lambda': [0.1, 0.2]\n",
    "    }\n",
    "\n",
    "    # Define models\n",
    "    # rf = RandomForestClassifier(random_state=42)\n",
    "    # xgb = XGBClassifier(random_state=42)\n",
    "\n",
    "    rf = RandomForestClassifier(random_state=42, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=91)\n",
    "    xgb = XGBClassifier(random_state=42, colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=100, reg_alpha=0.1, reg_lambda=0.1, subsample=0.8)\n",
    "\n",
    "    # Perform GridSearchCV for Random Forest\n",
    "    if gridSearch:\n",
    "        rf_grid_search = GridSearchCV(estimator=rf, param_grid=rf_param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "        rf_grid_search.fit(X_train, y_train)\n",
    "        best_rf = rf_grid_search.best_estimator_\n",
    "    else: \n",
    "        rf.fit(X_train, y_train)\n",
    "\n",
    "    # Perform GridSearchCV for XGBoost\n",
    "    if gridSearch:\n",
    "        xgb_grid_search = GridSearchCV(estimator=xgb, param_grid=xgb_param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "        xgb_grid_search.fit(X_train, y_train)\n",
    "        best_xgb = xgb_grid_search.best_estimator_\n",
    "    else:\n",
    "        xgb.fit(X_train, y_train)\n",
    "\n",
    "    # Create the ensemble with best estimators\n",
    "    ensemble_model = VotingClassifier(estimators=[('rf', rf), ('xgb', xgb)], voting='soft')\n",
    "    ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the ensemble\n",
    "    if showModelScores:\n",
    "        print(\"Model 2 : Train score:\", ensemble_model.score(X_train, y_train))\n",
    "        print(\"Model 2 : Test score:\", ensemble_model.score(X_test, y_test))\n",
    "\n",
    "    # Cross-validation\n",
    "    \n",
    "    if cvTest:\n",
    "        ensemble_cv_scores = cross_val_score(ensemble_model, X, y, cv=5)\n",
    "    \n",
    "    if showModelScores:\n",
    "        print(\"Model 2 : Cross-validation scores:\", ensemble_cv_scores)\n",
    "        print(\"Model 2 : Mean cross-validation score:\", ensemble_cv_scores.mean())\n",
    "\n",
    "    df['Signal'] = 0\n",
    "    # df.loc[X_test.index, 'Signal'] = model.predict(X_test) ## Model 1 Random Forest\n",
    "    # df.loc[X_test.index, 'Signal'] = ensemble_model1.predict(X_test) ## Model 2 Random Forest + XGBoost\n",
    "    df.loc[X_test.index, 'Signal'] = ensemble_model.predict(X_test) ## Model 3 More precise Random Forest + XGBoost \n",
    "\n",
    "    # Initialize the 'Position' column\n",
    "    df['Position'] = 0\n",
    "\n",
    "\n",
    "    ## Iterate through the DataFrame to apply the conditions\n",
    "    holding_position = False\n",
    "\n",
    "    start_idx = df.index.get_loc(X_test.index[0])\n",
    "\n",
    "    ## Condition 1\n",
    "    # for i in range(1, len(df)): \n",
    "    for i in range(start_idx, len(df)):\n",
    "        if df.loc[df.index[i], 'VIX'] > 40:\n",
    "            # print(df.index[i], '> 40')\n",
    "            if df.loc[df.index[i], 'VIX'] > 60 and not holding_position:\n",
    "                df.loc[df.index[i], 'Position'] = 1\n",
    "                holding_position = True\n",
    "            elif df.loc[df.index[i], 'VIX'] > 50 and holding_position:\n",
    "                df.loc[df.index[i], 'Position'] = 0\n",
    "                holding_position = False\n",
    "            elif df.loc[df.index[i], 'Signal'] == 1 and not holding_position and df.loc[df.index[i], 'VIX'] < 50:\n",
    "            # elif not holding_position and df.loc[df.index[i], 'VIX'] < 50:\n",
    "                df.loc[df.index[i], 'Position'] = 1\n",
    "                holding_position = True\n",
    "        elif (df.loc[df.index[i], 'VIX'] < 20) and holding_position:\n",
    "            ## or df.loc[df.index[i], 'Signal'] == 0\n",
    "            df.loc[df.index[i], 'Position'] = 0\n",
    "            holding_position = False\n",
    "    \n",
    "    # print(df[df['Signal'] == 1])\n",
    "    \n",
    "    # for i in range(1, len(df)): \n",
    "    #     if df.loc[df.index[i], 'VIX'] > 20:\n",
    "    #     # or df.loc[df.index[i], 'Signal'] == 1:\n",
    "    #         df.loc[df.index[i], 'Position'] = 1\n",
    "    #         holding_position = True\n",
    "    #     elif (df.loc[df.index[i], 'VIX'] < 10 ) and holding_position:\n",
    "    #         ## or df.loc[df.index[i], 'Signal'] == 0\n",
    "    #         df.loc[df.index[i], 'Position'] = 0\n",
    "    #         holding_position = False\n",
    "            \n",
    "    # df['Position'] = df['Position'].replace(to_replace=0, method=None, limit=None)\n",
    "    df.loc[df['Position'] == 0, 'Position'] = np.nan\n",
    "\n",
    "    # Forward fill NaN values in 'Position'\n",
    "    df['Position'] = df['Position'].fillna(method='ffill')\n",
    "\n",
    "    # Replace any remaining NaN values with 0 and ensure integer type\n",
    "    df['Position'] = df['Position'].fillna(0).astype(int)\n",
    "\n",
    "    # # Calculate strategy returns\n",
    "    # df['Strategy_Returns'] = df['Position'].shift(1) * df['Close'].pct_change()\n",
    "\n",
    "    # # Drop NaN values from returns\n",
    "    # df.dropna(subset=['Strategy_Returns'], inplace=True)\n",
    "\n",
    "    # returns = df['Strategy_Returns']\n",
    "    df_test_period = df.loc[X_test.index[0]:]\n",
    "\n",
    "    # Create a deep copy of the DataFrame to avoid the warning\n",
    "    df_test_period = df_test_period.copy()\n",
    "\n",
    "    # Calculate the strategy returns\n",
    "    df_test_period.loc[:, 'Strategy_Returns'] = df_test_period['Position'].shift(1) * df_test_period['Close'].pct_change()\n",
    "\n",
    "    # Drop rows with NaN values in 'Strategy_Returns' column\n",
    "    df_test_period.dropna(subset=['Strategy_Returns'], inplace=True)\n",
    "\n",
    "    # Extract the 'Strategy_Returns' column\n",
    "    returns = df_test_period['Strategy_Returns']\n",
    "    \n",
    "    cumulative_returns = (1 + returns).cumprod() - 1\n",
    "    perf_stats = {\n",
    "        'Annual Return': ep.annual_return(returns),\n",
    "        'Cumulative Returns': ep.cum_returns_final(returns),\n",
    "        'Annual Volatility': ep.annual_volatility(returns),\n",
    "        'Sharpe Ratio': ep.sharpe_ratio(returns),\n",
    "        'Sortino Ratio': ep.sortino_ratio(returns),\n",
    "        'Max Drawdown': ep.max_drawdown(returns),\n",
    "        'Calmar Ratio': ep.calmar_ratio(returns)\n",
    "    }\n",
    "\n",
    "    # res = pd.DataFrame()\n",
    "    \n",
    "    # res['Ticker'] = ticker\n",
    "    \n",
    "    # for metric, value in perf_stats.items():\n",
    "    #     # print(f\"{metric}: {value}\") \n",
    "    #     res[metric] = value\n",
    "    \n",
    "    # Convert perf_stats to a DataFrame\n",
    "    perf_df = pd.DataFrame(perf_stats, index=[ticker])\n",
    "    \n",
    "    perf_df['Index Name'] = tickerName\n",
    "    \n",
    "    perf_df['1_Train'] = model.score(X_train,y_train)\n",
    "    perf_df['1_Test'] = model.score(X_test,y_test)\n",
    "\n",
    "    if cvTest: \n",
    "        perf_df['1_CV'] = cv_scores.mean()\n",
    "    \n",
    "    perf_df['2_Train'] = ensemble_model.score(X_train, y_train)\n",
    "    perf_df['2_Test'] = ensemble_model.score(X_test, y_test)\n",
    "\n",
    "    if cvTest:\n",
    "        perf_df['2_CV'] = ensemble_cv_scores.mean()\n",
    "\n",
    "    perf_df['Test Date'] = str(X_test.index[0])\n",
    "    \n",
    "    perf_df = perf_df[['Index Name'] + [col for col in perf_df.columns if col != 'Index Name']]\n",
    "    \n",
    "    # Append to all_data DataFrame\n",
    "    all_data = pd.concat([all_data, perf_df])\n",
    "\n",
    "    print(f\"{ep.annual_return(returns):.5f} {ep.annual_volatility(returns):.5f} {ep.sharpe_ratio(returns):.5f} {ep.max_drawdown(returns):.5f} \")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data.to_csv(\"indices_return.csv\")\n",
    "all_data.to_excel(\"indices_return.xlsx\", index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
