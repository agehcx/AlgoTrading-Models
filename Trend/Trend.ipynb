{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pyfolio as pf\n",
    "import pandas_ta as ta\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "import empyrical as ep\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import plotly.express as px\n",
    "\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = \"2019-1-1\"\n",
    "df = yf.download(tickers=\"AAPL\", start=start)\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "max_drawdown = 30\n",
    "\n",
    "x = len(df)\n",
    "\n",
    "trend = ''\n",
    "\n",
    "Peak = -np.inf\n",
    "date_Peak = 0\n",
    "Trough = np.inf\n",
    "date_Trough = 0\n",
    "\n",
    "ddd = np.empty((0, 3), np.datetime64)\n",
    "\n",
    "for i in range(0, x):\n",
    "    up = 0\n",
    "    dn = 0\n",
    "    \n",
    "    if trend == '' or trend == 'bull':\n",
    "        if df.loc[i, 'Close'] >= Peak:\n",
    "            Peak = df.loc[i, 'Close']\n",
    "            date_Peak = df.loc[i, 'Date']\n",
    "            \n",
    "    if trend == '' or trend == 'bear':\n",
    "        if df.loc[i, 'Close'] <= Trough:\n",
    "            Trough = df.loc[i, 'Close']\n",
    "            date_Trough = df.loc[i, 'Date']\n",
    "            \n",
    "    if Peak != -np.inf:\n",
    "        dn = (Peak - df.loc[df.index[i], 'Close']) / (Peak / 100.0)\n",
    "        \n",
    "    if Trough != np.inf:\n",
    "        up = (df.loc[df.index[i], 'Close'] - Trough) / (Trough / 100.0)\n",
    "\n",
    "    if up >= max_drawdown:\n",
    "        trend = 'bull'\n",
    "        ddd = np.append(ddd, np.array([[date_Trough, df.loc[i, 'Date'], 1]]), axis=0)\n",
    "        Trough = np.inf\n",
    "        Peak = df.loc[df.index[i], 'Close']\n",
    "        date_Peak = df.loc[i, 'Date']\n",
    "        \n",
    "    if dn >= max_drawdown:\n",
    "        trend = 'bear'\n",
    "        ddd = np.append(ddd, np.array([[date_Peak, df.loc[i, 'Date'], 2]]), axis=0)\n",
    "        Peak = -np.inf\n",
    "        Trough = df.loc[df.index[i], 'Close']\n",
    "        date_Trough = df.loc[i, 'Date']\n",
    "\n",
    "\n",
    "df = df.set_index('Date')\n",
    "up_trend_s = ddd[ddd[:, 2] == 1, 0]\n",
    "up_trend_f = ddd[ddd[:, 2] == 1, 1]\n",
    "dn_trend_s = ddd[ddd[:, 2] == 2, 0]\n",
    "dn_trend_f = ddd[ddd[:, 2] == 2, 1]\n",
    "\n",
    "if ddd[len(ddd) - 1, 2] == 1:\n",
    "    # if the trend is growing, then we are looking for a local maximum\n",
    "    \n",
    "    ind = up_trend_f[len(up_trend_f) - 1] #get the index of the beginning of the bullish trend\n",
    "    imax = df.loc[ind:, 'Close'].idxmax() #local maximum\n",
    "    \n",
    "    if df.loc[imax, 'Close'] > df.loc[ind, 'Close']: #if the high is greater than the price of the beginning of the bullish trend, then add a peak\n",
    "        dn_trend_s = np.append(dn_trend_s, imax)\n",
    "        \n",
    "else:\n",
    "    ind = dn_trend_f[len(dn_trend_f) - 1]#bear market\n",
    "    imin = df.loc[ind:, 'Close'].idxmin()\n",
    "    if df.loc[imin, 'Close'] < df.loc[ind, 'Close']:\n",
    "        up_trend_s = np.append(up_trend_s, imin)\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(df.index, df['Close'])\n",
    "ax.plot(up_trend_s, df.loc[up_trend_s, 'Close'], 'x', color='lime')\n",
    "ax.plot(up_trend_f, df.loc[up_trend_f, 'Close'], 'o', color='lime', markersize=4)\n",
    "ax.plot(dn_trend_s, df.loc[dn_trend_s, 'Close'], 'x', color='red')\n",
    "ax.plot(dn_trend_f, df.loc[dn_trend_f, 'Close'], 'o', color='red', markersize=4)\n",
    "fig.autofmt_xdate()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = yf.Ticker(\"^IXIC\") ## NASDAQ Composite (0.07133)\n",
    "# dft = yf.Ticker(\"^GSPC\") ## S&P 500\n",
    "# dft = yf.Ticker(\"TDEX.BK\") ## TDEX\n",
    "# dft = yf.Ticker(\"^DJI\") ## Dow Jones Industrial Average \n",
    "# dft = yf.Ticker(\"AWC.BK\") ## Asset World Corp Public Company Limited\n",
    "\n",
    "\n",
    "tickers = {\n",
    "    \"^GSPC\": \"S&P 500\",\n",
    "    \"^DJI\": \"Dow Jones Industrial Average\",\n",
    "    \"^IXIC\": \"NASDAQ Composite\",\n",
    "    \"^NYA\": \"NYSE COMPOSITE (DJ)\",\n",
    "    \"^XAX\": \"NYSE AMEX COMPOSITE INDEX\",\n",
    "    \"^BUK100P\": \"Cboe UK 100\",\n",
    "    \"^RUT\": \"Russell 2000\",\n",
    "    \"^VIX\": \"CBOE Volatility Index\",\n",
    "    \"^FTSE\": \"FTSE 100\",\n",
    "    \"^GDAXI\": \"DAX PERFORMANCE-INDEX\",\n",
    "    \"^FCHI\": \"CAC 40\",\n",
    "    \"^STOXX50E\": \"ESTX 50 PR.EUR\",\n",
    "    \"^N100\": \"Euronext 100 Index\",\n",
    "    \"^BFX\": \"BEL 20\",\n",
    "    \"IMOEX.ME\": \"MOEX Russia Index\",\n",
    "    \"^N225\": \"Nikkei 225\",\n",
    "    \"^HSI\": \"HANG SENG INDEX\",\n",
    "    \"000001.SS\": \"SSE Composite Index\",\n",
    "    \"399001.SZ\": \"Shenzhen Index\",\n",
    "    \"^STI\": \"STI Index\",\n",
    "    \"^AXJO\": \"S&P/ASX 200\",\n",
    "    \"^AORD\": \"ALL ORDINARIES\",\n",
    "    \"^BSESN\": \"S&P BSE SENSEX\",\n",
    "    \"^JKSE\": \"IDX COMPOSITE\",\n",
    "    \"^KLSE\": \"FTSE Bursa Malaysia KLCI\",\n",
    "    \"^NZ50\": \"S&P/NZX 50 INDEX GROSS (GROSS)\",\n",
    "    \"^KS11\": \"KOSPI Composite Index\",\n",
    "    \"^TWII\": \"TSEC weighted index\",\n",
    "    \"^GSPTSE\": \"S&P/TSX Composite index\",\n",
    "    \"^BVSP\": \"IBOVESPA\",\n",
    "    \"^MXX\": \"IPC MEXICO\",\n",
    "    \"^IPSA\": \"S&P/CLX IPSA\",\n",
    "    \"^MERV\": \"MERVAL\",\n",
    "    \"^TA125.TA\": \"TA-125\",\n",
    "    \"^CASE30\": \"EGX 30 Price Return Index\",\n",
    "    \"^JN0U.JO\": \"Top 40 USD Net TRI Index\"\n",
    "}\n",
    "\n",
    "ticker_name = dft.info.get(\"longName\", \"Unknown Ticker\")\n",
    "print(ticker_name)\n",
    "\n",
    "# # Define the start and end dates for the data\n",
    "startDate = \"1990-01-01\"\n",
    "endDate = \"2024-01-01\"\n",
    "\n",
    "timeZone = dft.info.get(\"timeZoneFullName\")\n",
    "print(timeZone)\n",
    "\n",
    "df = dft.history(interval=\"1d\", start=startDate, end=endDate)\n",
    "\n",
    "# Comparing Timestamp\n",
    "# start_timestamp = int(datetime.datetime.strptime(startDate, \"%Y-%m-%d\").timestamp())\n",
    "# print(start_timestamp)\n",
    "# timestamp1 = 315550800\n",
    "# timestamp2 = 315507600\n",
    "# date1 = datetime.datetime.fromtimestamp(timestamp1)\n",
    "# date2 = datetime.datetime.fromtimestamp(timestamp2)\n",
    "# print(f\"Timestamp 1: {timestamp1} -> Date 1: {date1}\")\n",
    "# print(f\"Timestamp 2: {timestamp2} -> Date 2: {date2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Dividends column\n",
    "df.drop(columns=['Dividends'], inplace=True)\n",
    "\n",
    "# Drop Stock Splits column\n",
    "df.drop(columns=['Stock Splits'], inplace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate EMA-12 and EMA-26 using Exponential Weighing Average (EWM)\n",
    "# df['EMA-12'] = df['Close'].ewm(span = 12, adjust = False).mean()\n",
    "# df['EMA-26'] = df['Close'].ewm(span = 26, adjust = False).mean()\n",
    "\n",
    "## Calculate MACD \n",
    "# df['MACD'] = df['EMA-12'] - df['EMA-26']\n",
    "df['MACD'] = ta.macd(df['Close'], fast=12, slow=26, signal=9)['MACD_12_26_9']\n",
    "df['Pct_Change'] = df['Close'].pct_change() * 100\n",
    "\n",
    "## Calculate RSI using formula\n",
    "## RSI = 100 – [100 ÷ ( 1 + (Average Gain During Up Periods ÷ Average Loss During Down Periods ))]\n",
    "\n",
    "delta = df['Close'].diff()\n",
    "gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "rs = gain / loss\n",
    "df['RSI'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "delta = df['Close'].diff()\n",
    "gain = delta.where(delta > 0, 0)\n",
    "loss = -delta.where(delta < 0, 0)\n",
    "\n",
    "# Calculate the Exponential Moving Average of gains and losses\n",
    "avg_gain = gain.ewm(span=14, min_periods=14).mean()\n",
    "avg_loss = loss.ewm(span=14, min_periods=14).mean()\n",
    "\n",
    "# Calculate the RS and RSI\n",
    "rs = avg_gain / avg_loss\n",
    "df['RSI_EMA'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "df['RSI_ta'] = ta.rsi(df['Close'], length=14)\n",
    "\n",
    "df['MA10'] = df.ta.sma(length=10)\n",
    "df['MA50'] = df.ta.sma(length=50)\n",
    "df['MA200'] = df.ta.sma(length=200)\n",
    "\n",
    "## Calculate Boilinger Bands\n",
    "window = 20\n",
    "df['MA20'] = df['Close'].rolling(window=window).mean()\n",
    "df['std_dev'] = df['Close'].rolling(window=window).std()\n",
    "df['Upper_BB'] = df['MA20'] + (df['std_dev'] * 2)\n",
    "df['Lower_BB'] = df['MA20'] - (df['std_dev'] * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Close', 'MACD', 'RSI','RSI_EMA','RSI_ta']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target variable: 1 if next day's close is higher than today's, else 0\n",
    "df['Target'] = (df['Close'].shift(-1) > df['Close']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch VIX index data\n",
    "vix = yf.Ticker(\"^VIX\")\n",
    "vix_df = vix.history(interval=\"1d\", start=startDate, end=endDate)\n",
    "\n",
    "vix_df['Pct_Change'] = vix_df['Close'].pct_change() * 100\n",
    "\n",
    "# print(vix_df['Pct_Change'].max())\n",
    "\n",
    "\n",
    "import pytz\n",
    "\n",
    "# Get the time zone of the stock's exchange\n",
    "stock_timezone = pytz.timezone(timeZone)\n",
    "\n",
    "# Convert the time zone of the VIX DataFrame to match the time zone of the stock's exchange\n",
    "vix_df.index = vix_df.index.tz_convert(stock_timezone)\n",
    "\n",
    "# Align the timestamps of the VIX data to match those of your DataFrame\n",
    "vix_df = vix_df.reindex(df.index, method='ffill')\n",
    "\n",
    "# Merge VIX close prices into the original DataFrame\n",
    "df['VIX'] = vix_df['Close']\n",
    "\n",
    "\n",
    "\n",
    "# # df.index = df.index.tz_convert('UTC')\n",
    "# # # vix_df.index = vix_df.index.tz_convert('UTC')\n",
    "# # # vix_df.index = vix_df.index.tz_convert('Asia/Bangkok')\n",
    "# # vix_df.index = vix_df.index.tz_convert('Asia/Beijing')\n",
    "\n",
    "# # # Shift the timestamps of vix_df by one hour\n",
    "# # vix_df.index = vix_df.index - pd.Timedelta(hours=1)\n",
    "\n",
    "\n",
    "# # # Merge VIX close prices into the original DataFrame\n",
    "# # # df['VIX'] = vix_df['Close']\n",
    "\n",
    "# # df = df.join(vix_df[['Close']], rsuffix='_VIX')\n",
    "\n",
    "# # Rename the VIX close column\n",
    "# df.rename(columns={'Close_VIX': 'VIX'}, inplace=True)\n",
    "\n",
    "vix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20,6))\n",
    "# plt.plot(df['Close'], label=\"Closed Price\")\n",
    "# mx = df['Close'].max()\n",
    "# plt.plot(vix_df['Close'] * mx / 100, label=\"VIX Index\")\n",
    "# plt.legend()\n",
    "# plt.title(f\"VIX Index and {ticker_name} Price (Adjusted Index)\")\n",
    "# plt.show()\n",
    "\n",
    "# Create the plotly figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add the closed price line\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df.index, \n",
    "    y=df['Close'], \n",
    "    mode='lines', \n",
    "    name='Closed Price',\n",
    "    hovertemplate='%{x|%Y-%m-%d}<br>Price: %{y}'\n",
    "))\n",
    "\n",
    "mx = df['Close'].max()\n",
    "\n",
    "# Add the VIX index line, Scaled out of Max stock price\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=vix_df.index, \n",
    "    y=vix_df['Close'] * mx / 100, \n",
    "    mode='lines', \n",
    "    name='VIX',\n",
    "    hovertemplate='%{x|%Y-%m-%d}<br>VIX Index: %{customdata:.2f}',\n",
    "    customdata=vix_df['Close']  # Use the real VIX values as customdata\n",
    "))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title=f\"VIX Index to {ticker_name} Price (Adjusted Index)\",\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"Price\",\n",
    "    legend_title=\"Legend\",\n",
    "    width=2100,\n",
    "    height=700\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(25,10))\n",
    "# plt.plot(vix_df['Pct_Change'], label=\"VIX Index\")\n",
    "# plt.legend()\n",
    "# plt.title(\"VIX Index Percentage Change\")\n",
    "# plt.show()\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=vix_df.index, y=vix_df['Close'], mode='lines', name='Percentage Change'))\n",
    "fig.update_layout(\n",
    "    title=f\"VIX Index Closed Price\",\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"Percentage Change\",\n",
    "    legend_title=\"Legend\",\n",
    "    width=3500,\n",
    "    height=700\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Main DataFrame Index:\", df.index)\n",
    "# print(\"VIX DataFrame Index:\", vix_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df.index,\n",
    "    y=df['Close'],\n",
    "    mode='lines',\n",
    "    line=dict(color='cyan'),\n",
    "    name=f\"{ticker_name} Price\")\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"{ticker_name} Price\",\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"Price\",\n",
    "    width=1200,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Plot the VIX index\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=vix_df.index,\n",
    "    y=vix_df['Close'],\n",
    "    mode='lines',\n",
    "    line=dict(color='purple'),\n",
    "    name='VIX Index')\n",
    ")\n",
    "\n",
    "prev_vix = None\n",
    "gt_vix_date = []\n",
    "xtr_vix_date = []\n",
    "\n",
    "# Iterate through the VIX data\n",
    "for date, vix_value in vix_df['Close'].items():\n",
    "    if vix_value >= 65 and (prev_vix is None or prev_vix < 65):\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[date],\n",
    "            y=[vix_value],\n",
    "            mode='markers',\n",
    "            marker=dict(color='green', symbol='x'),\n",
    "            name=str(date)  # Convert Timestamp to string\n",
    "        ))\n",
    "        xtr_vix_date.append([date, vix_value])\n",
    "    elif vix_value >= 35 and (prev_vix is None or prev_vix < 35):\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[date],\n",
    "            y=[vix_value],\n",
    "            mode='markers',\n",
    "            marker=dict(color='red', symbol='circle'),\n",
    "            name=str(date)  # Convert Timestamp to string\n",
    "        ))\n",
    "        gt_vix_date.append([date, vix_value])\n",
    "    prev_vix = vix_value\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"VIX Index\",\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"VIX Value\",\n",
    "    width=4200,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any row with NaN value\n",
    "df = df.dropna()\n",
    "\n",
    "# Print out list where the VIX is greater than 30\n",
    "gt_vix = df[df['VIX'] > 30]\n",
    "# gt_vix\n",
    "\n",
    "gt_vix_df = pd.DataFrame(gt_vix_date, columns=['Date', 'VIX'])\n",
    "gt_vix_df.set_index('Date', inplace=True)\n",
    "\n",
    "# Convert xtr_vix_date to DataFrame\n",
    "xtr_vix_df = pd.DataFrame(xtr_vix_date, columns=['Date', 'VIX'])\n",
    "xtr_vix_df.set_index('Date', inplace=True)\n",
    "\n",
    "# df['VIX_35'] = df.index.isin(gt_vix_df.index)\n",
    "# df['VIX_65'] = df.index.isin(xtr_vix_df.index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvTest = False\n",
    "\n",
    "\n",
    "if not cvTest:\n",
    "    cv_scores = np.array([0.0, 0.0])\n",
    "    md2_cv_scores = np.array([0.0, 0.0])\n",
    "    ensemble1_cv_scores = np.array([0.0, 0.0])\n",
    "    ensemble_cv_scores = np.array([0.0, 0.0])\n",
    "    \n",
    "# Prepare the feature set and target variable\n",
    "X = df[['Pct_Change', 'std_dev', 'MA200', 'MA50', 'MA10', 'MACD', 'RSI_ta', 'VIX']]\n",
    "# X = df[['Pct_Change', 'std_dev', 'MA200', 'MA50', 'MA10', 'MACD', 'RSI_ta', 'VIX']]\n",
    "# X = df[['MA200', 'MA50', 'MA10', 'MACD2', 'RSI_ta', 'VIX', 'VIX_35', 'VIX_65']]\n",
    "# X = df[['SMA200', 'SMA50', 'SMA10', 'MACD', 'RSI', 'VIX', 'VIX_35', 'VIX_65', 'MA20', 'Lower_BB', 'Upper_BB']]\n",
    "y = df['Target']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Train the RandomForestClassifier\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100, \n",
    "    random_state=42, \n",
    "    max_depth=5, \n",
    "    min_samples_leaf=1, \n",
    "    min_samples_split=10\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train score : \", model.score(X_train,y_train))\n",
    "print(\"Test score : \", model.score(X_test,y_test))\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "if cvTest:\n",
    "    cv_scores = cross_val_score(model, X, y, cv=5)\n",
    "    print(\"Cross-validation scores:\", cv_scores)\n",
    "    print(\"Mean cross-validation score:\", cv_scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check feature importances\n",
    "importances = model.feature_importances_\n",
    "feature_names = X.columns\n",
    "feature_importance = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "print(feature_importance.sort_values(by='Importance', ascending=False))\n",
    "\n",
    "# Hyperparameter tuning example using GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5, 7, 9, 11, 13, 15],\n",
    "    'min_samples_split': [1, 2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "# print(\"Best parameters found: \", grid_search.best_params_)\n",
    "# print(\"Best cross-validation score: \", grid_search.best_score_)\n",
    "\n",
    "# # Re-train the model with the best parameters\n",
    "# best_model = grid_search.best_estimator_\n",
    "# best_model.fit(X_train, y_train)\n",
    "# print(\"Train score with best parameters: \", best_model.score(X_train, y_train))\n",
    "# print(\"Test score with best parameters: \", best_model.score(X_test, y_test))\n",
    "\n",
    "\n",
    "\n",
    "# Output\n",
    "\n",
    "# Feature  Importance\n",
    "# 4     RSI    0.207028\n",
    "# 3    MACD    0.173785\n",
    "# 5     VIX    0.161541\n",
    "# 0  SMA200    0.156257\n",
    "# 2   SMA10    0.150279\n",
    "# 1   SMA50    0.146876\n",
    "# 6  VIX_35    0.002741\n",
    "# 7  VIX_65    0.001494\n",
    "# Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
    "# Best parameters found:  {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}\n",
    "# Best cross-validation score:  0.513870182753551\n",
    "# Train score with best parameters:  0.5857438016528925\n",
    "# Test score with best parameters:  0.5050147492625369"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Initialize XGBClassifier\n",
    "xgb_model = XGBClassifier(random_state=42)\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
    "    'max_depth': [3, 5, 7],            # Maximum depth of a tree\n",
    "    'learning_rate': [0.1, 0.01, 0.001], # Learning rate\n",
    "    'subsample': [0.8, 0.9],           # Subsample ratio of the training instances\n",
    "    'colsample_bytree': [0.8, 0.9],    # Subsample ratio of columns when constructing each tree\n",
    "    'gamma': [0.1, 0.2],               # Minimum loss reduction required to make a further partition\n",
    "    'reg_alpha': [0.1, 0.2],           # L1 regularization term on weights\n",
    "    'reg_lambda': [0.1, 0.2]           # L2 regularization term on weights\n",
    "}\n",
    "\n",
    "# # Perform grid search with cross-validation\n",
    "# grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Get the best parameters and score\n",
    "# best_params = grid_search.best_params_\n",
    "# best_score = grid_search.best_score_\n",
    "\n",
    "# # Print the best parameters and score\n",
    "# print(\"Best Parameters:\", best_params)\n",
    "# print(\"Best Score:\", best_score)\n",
    "\n",
    "# # Evaluate the model with the best parameters\n",
    "# best_xgb_model = grid_search.best_estimator_\n",
    "# print(\"XGB Train score:\", best_xgb_model.score(X_train, y_train))\n",
    "# print(\"XGB Test score:\", best_xgb_model.score(X_test, y_test))\n",
    "\n",
    "# Output\n",
    "\n",
    "# Best Parameters: {'colsample_bytree': 0.8, \n",
    "#     'gamma': 0.1, \n",
    "#     'learning_rate': 0.001, \n",
    "#     'max_depth': 3, \n",
    "#     'n_estimators': 100, \n",
    "#     'reg_alpha': 0.1, \n",
    "#     'reg_lambda': 0.1, \n",
    "#     'subsample': 0.8 \n",
    "# }\n",
    "# Best Score: 0.5494392014716607\n",
    "# XGB Train score: 0.5494391971664699\n",
    "# XGB Test score: 0.5510324483775811\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"scaler\", MinMaxScaler()), \n",
    "    (\"classifier\", KNeighborsClassifier())\n",
    "]) \n",
    "pipe.fit(X_train, y_train)\n",
    "class_names = pipe.classes_\n",
    "class_names\n",
    "y_pred = pipe.predict(X_test)\n",
    "acc_train = accuracy_score(y_train, pipe.predict(X_train))\n",
    "acc_test = accuracy_score(y_test, y_pred)\n",
    "print(f'Train Accuracy: {acc_train:0.4}, Test Accuracy: {acc_test:0.4}')\n",
    "\n",
    "if cvTest:\n",
    "    md2_cv_scores = cross_val_score(model, X, y, cv=5)\n",
    "    print(\"Cross-validation scores:\", md2_cv_scores)\n",
    "    print(\"Mean cross-validation score:\", md2_cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Define the models\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=5)\n",
    "xgb = XGBClassifier(random_state=42, n_estimators=100, max_depth=5, learning_rate=0.00825)\n",
    "\n",
    "# Create the ensemble\n",
    "ensemble_model1 = VotingClassifier(estimators=[('rf', rf), ('xgb', xgb)], voting='soft')\n",
    "\n",
    "# Fit the ensemble\n",
    "ensemble_model1.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the ensemble\n",
    "print(\"Ensemble Train score:\", ensemble_model1.score(X_train, y_train))\n",
    "print(\"Ensemble Test score:\", ensemble_model1.score(X_test, y_test))\n",
    "\n",
    "if cvTest:\n",
    "    # Cross-validation\n",
    "    ensemble1_cv_scores = cross_val_score(ensemble_model1, X, y, cv=5)\n",
    "    print(\"Ensemble Cross-validation scores:\", ensemble1_cv_scores)\n",
    "    print(\"Ensemble Mean cross-validation score:\", ensemble1_cv_scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Define hyperparameters grid for Random Forest\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Define hyperparameters grid for XGBoost\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.1, 0.01, 0.001, 0.005, 0.0025, 0.00125],\n",
    "    'subsample': [0.8, 0.9],\n",
    "    'colsample_bytree': [0.8, 0.9],\n",
    "    'gamma': [0.1, 0.2],\n",
    "    'reg_alpha': [0.1, 0.2],\n",
    "    'reg_lambda': [0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Define models\n",
    "# rf = RandomForestClassifier(random_state=42)\n",
    "# xgb = XGBClassifier(random_state=42)\n",
    "\n",
    "gridSearch = False\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42, max_depth=5, \n",
    "                            min_samples_leaf=1, min_samples_split=5, \n",
    "                            n_estimators=91)\n",
    "\n",
    "xgb = XGBClassifier(random_state=42, colsample_bytree=0.8, \n",
    "                    gamma=0.1, learning_rate=0.001, \n",
    "                    max_depth=3, n_estimators=100, \n",
    "                    reg_alpha=0.1, reg_lambda=0.1, \n",
    "                    subsample=0.8)\n",
    "\n",
    "# Perform GridSearchCV for Random Forest\n",
    "if gridSearch:\n",
    "    rf_grid_search = GridSearchCV(estimator=rf, param_grid=rf_param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    rf_grid_search.fit(X_train, y_train)\n",
    "    best_rf = rf_grid_search.best_estimator_\n",
    "else: \n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "# Perform GridSearchCV for XGBoost\n",
    "if gridSearch:\n",
    "    xgb_grid_search = GridSearchCV(estimator=xgb, param_grid=xgb_param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    xgb_grid_search.fit(X_train, y_train)\n",
    "    best_xgb = xgb_grid_search.best_estimator_\n",
    "else:\n",
    "    xgb.fit(X_train, y_train)\n",
    "\n",
    "# Create the ensemble with best estimators\n",
    "ensemble_model = VotingClassifier(estimators=[('rf', rf), ('xgb', xgb)], voting='soft')\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the ensemble\n",
    "print(\"Ensemble Train score:\", ensemble_model.score(X_train, y_train))\n",
    "print(\"Ensemble Test score:\", ensemble_model.score(X_test, y_test))\n",
    "\n",
    "# Cross-validation\n",
    "if cvTest:\n",
    "    ensemble_cv_scores = cross_val_score(ensemble_model, X, y, cv=5)\n",
    "    print(\"Ensemble Cross-validation scores:\", ensemble_cv_scores)\n",
    "    print(\"Ensemble Mean cross-validation score:\", ensemble_cv_scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(rf_grid_search.best_params_)\n",
    "# {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
    "\n",
    "# print(xgb_grid_search.best_params_)\n",
    "# {'colsample_bytree': 0.8, 'gamma': 0.1, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100, 'reg_alpha': 0.1, 'reg_lambda': 0.1, 'subsample': 0.8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model 1\")\n",
    "print(f\"Train score : {model.score(X_train,y_train):0.5} \\nTest score  : {model.score(X_test,y_test):0.5}\")\n",
    "if cvTest: print(f\"CV Score    : {cv_scores.mean():0.5}\\n\")\n",
    "\n",
    "print(\"Model 2\")\n",
    "print(f\"Train score : {acc_train:0.5} \\nTest score  : {acc_test:0.5}\")\n",
    "if cvTest: print(f\"CV Score    : {md2_cv_scores.mean():0.5}\\n\")\n",
    "\n",
    "print(\"Model 3\")\n",
    "print(f\"Train score : {ensemble_model1.score(X_train, y_train):0.5} \\nTest score  : {ensemble_model1.score(X_test, y_test):0.5}\")\n",
    "if cvTest: print(f\"CV Score    : {ensemble1_cv_scores.mean():0.5}\\n\")\n",
    "\n",
    "print(\"Model 4\")\n",
    "print(f\"Train score : {ensemble_model.score(X_train, y_train):0.5} \\nTest score  : {ensemble_model.score(X_test, y_test):0.5}\")\n",
    "if cvTest: print(f\"CV Score    : {ensemble_cv_scores.mean():0.5}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Create the figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add bars for each model with different colors\n",
    "fig.add_trace(go.Bar(\n",
    "    x=['Train', 'Test', 'CV'],\n",
    "    y=[\n",
    "        model.score(X_train, y_train), \n",
    "        model.score(X_test, y_test), \n",
    "        cv_scores.mean()\n",
    "    ],\n",
    "    name='Model 1',\n",
    "    marker_color='blue',\n",
    "    text=[model.score(X_train, y_train), model.score(X_test, y_test), cv_scores.mean()],\n",
    "    textposition='auto'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=['Train', 'Test', 'CV'],\n",
    "    y=[\n",
    "        acc_train, \n",
    "        acc_test, \n",
    "        md2_cv_scores.mean()\n",
    "    ],\n",
    "    name='Model 2',\n",
    "    marker_color='orange',\n",
    "    text=[acc_train, acc_test, md2_cv_scores.mean()],\n",
    "    textposition='auto'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=['Train', 'Test', 'CV'],\n",
    "    y=[\n",
    "        ensemble_model1.score(X_train, y_train), \n",
    "        ensemble_model1.score(X_test, y_test), \n",
    "        ensemble1_cv_scores.mean()\n",
    "    ],\n",
    "    name='Model 3',\n",
    "    marker_color='green',\n",
    "    text=[ensemble_model1.score(X_train, y_train), ensemble_model1.score(X_test, y_test), ensemble1_cv_scores.mean()],\n",
    "    textposition='auto'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=['Train', 'Test', 'CV'],\n",
    "    y=[\n",
    "        ensemble_model.score(X_train, y_train), \n",
    "        ensemble_model.score(X_test, y_test), \n",
    "        ensemble_cv_scores.mean()\n",
    "    ],\n",
    "    name='Model 4',\n",
    "    marker_color='red',\n",
    "    text=[ensemble_model.score(X_train, y_train), ensemble_model.score(X_test, y_test), ensemble_cv_scores.mean()],\n",
    "    textposition='auto'\n",
    "))\n",
    "\n",
    "# Update the layout\n",
    "fig.update_layout(\n",
    "    title='Model Scores Comparison',\n",
    "    xaxis_title='Score',\n",
    "    yaxis_title='Score out of 1.0',\n",
    "    barmode='group',\n",
    "    legend_title='Models',\n",
    "    xaxis=dict(\n",
    "        tickmode='array',\n",
    "        tickvals=['Train', 'Test', 'CV']\n",
    "    )\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['VIX'] > 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Signal'] = 0\n",
    "# df.loc[X_test.index, 'Signal'] = model.predict(X_test) ## Model 1 Random Forest\n",
    "# df.loc[X_test.index, 'Signal'] = ensemble_model1.predict(X_test) ## Model 2 Random Forest + XGBoost\n",
    "df.loc[X_test.index, 'Signal'] = ensemble_model.predict(X_test) ## Model 3 More precise Random Forest + XGBoost \n",
    "\n",
    "# Initialize the 'Position' column\n",
    "df['Position'] = 0\n",
    "\n",
    "\n",
    "\n",
    "## Iterate through the DataFrame to apply the conditions\n",
    "holding_position = False\n",
    "\n",
    "## Condition 1\n",
    "\n",
    "order_list = []\n",
    "\n",
    "start_idx = df.index.get_loc(X_test.index[0])\n",
    "\n",
    "# for i in range(1, len(df)): \n",
    "#     if df.loc[df.index[i], 'VIX'] > 30:\n",
    "#         # print(df.index[i])\n",
    "#         if df.loc[df.index[i], 'Signal'] == 1 and df.loc[df.index[i], 'VIX'] > 80 and not holding_position:\n",
    "#             order_list.append({df.index[i],'80'})\n",
    "#             df.loc[df.index[i], 'Position'] = 1\n",
    "#             holding_position = True\n",
    "#         elif df.loc[df.index[i], 'VIX'] > 70 and holding_position and df.loc[df.index[i], 'VIX'] <= 75:\n",
    "#             df.loc[df.index[i], 'Position'] = 0\n",
    "#             holding_position = False\n",
    "#         elif df.loc[df.index[i], 'Signal'] == 1 and df.loc[df.index[i], 'VIX'] > 70 and not holding_position:\n",
    "#             order_list.append({df.index[i],'70'})\n",
    "#             df.loc[df.index[i], 'Position'] = 1\n",
    "#             holding_position = True\n",
    "#         elif df.loc[df.index[i], 'VIX'] > 65 and holding_position and df.loc[df.index[i], 'VIX'] <= 70:\n",
    "#             df.loc[df.index[i], 'Position'] = 0\n",
    "#             holding_position = False\n",
    "#         elif df.loc[df.index[i], 'Signal'] == 1 and df.loc[df.index[i], 'VIX'] > 55 and not holding_position and df.loc[df.index[i], 'VIX'] <= 65:\n",
    "#             order_list.append({df.index[i],'55'})\n",
    "#             df.loc[df.index[i], 'Position'] = 1\n",
    "#             holding_position = True\n",
    "#         elif df.loc[df.index[i], 'VIX'] > 45 and holding_position:\n",
    "#             df.loc[df.index[i], 'Position'] = 0\n",
    "#             holding_position = False\n",
    "#         elif df.loc[df.index[i], 'Signal'] == 1 and not holding_position and df.loc[df.index[i], 'VIX'] <= 45:\n",
    "#         # elif not holding_position and df.loc[df.index[i], 'VIX'] < 50:\n",
    "#             order_list.append({df.index[i],'30'})\n",
    "#             df.loc[df.index[i], 'Position'] = 1\n",
    "#             holding_position = True\n",
    "#     # elif (df.loc[df.index[i], 'VIX'] < 20 or df.loc[df.index[i], 'Signal'] == 0) and holding_position:\n",
    "#     elif (df.loc[df.index[i], 'VIX'] < 20 ) and holding_position:\n",
    "#         df.loc[df.index[i], 'Position'] = 0\n",
    "#         holding_position = False\n",
    "        \n",
    "# for i in range(start_idx, len(df)): \n",
    "#     if df.loc[df.index[i], 'VIX'] > 30:\n",
    "#         print(\"40\")\n",
    "#         if df.loc[df.index[i], 'VIX'] > 50 and not holding_position:\n",
    "#             df.loc[df.index[i], 'Position'] = 1\n",
    "#             holding_position = True\n",
    "#         elif df.loc[df.index[i], 'VIX'] > 50 and holding_position:\n",
    "#             df.loc[df.index[i], 'Position'] = 0\n",
    "#             holding_position = False\n",
    "#         elif not holding_position and df.loc[df.index[i], 'VIX'] < 40:\n",
    "#         # elif df.loc[df.index[i], 'Signal'] == 1 and not holding_position and df.loc[df.index[i], 'VIX'] < 50:\n",
    "#             df.loc[df.index[i], 'Position'] = 1\n",
    "#             holding_position = True\n",
    "#     elif (df.loc[df.index[i], 'VIX'] < 20 ) and holding_position:\n",
    "#         df.loc[df.index[i], 'Position'] = 0\n",
    "#         holding_position = False\n",
    "    \n",
    "    ## or df.loc[df.index[i], 'Signal'] == 0\n",
    "##  Condition 2\n",
    "\n",
    "# for i in range(1, len(df)):\n",
    "#     if df.loc[df.index[i], 'Signal'] == 1 and df.loc[df.index[i], 'VIX'] > 35 and not holding_position:\n",
    "#         df.loc[df.index[i], 'Position'] = 1\n",
    "#         holding_position = True\n",
    "#     elif (df.loc[df.index[i], 'VIX'] < 20 or df.loc[df.index[i], 'Signal'] == 0) and holding_position:\n",
    "#     # if (df.loc[df.index[i], 'VIX'] < 20 ) and holding_position:\n",
    "#         # print(\"Closing position VIX less than 30 at : \", df.index[i])\n",
    "#         df.loc[df.index[i], 'Position'] = 0\n",
    "#         # print(df.loc[df.index[i], 'Position'])\n",
    "#         holding_position = False\n",
    "#     elif df.loc[df.index[i], 'VIX'] > 45 and holding_position:\n",
    "#         df.loc[df.index[i], 'Position'] = 0\n",
    "#         holding_position = False\n",
    "#     elif df.loc[df.index[i], 'VIX'] > 60 and not holding_position:\n",
    "#         df.loc[df.index[i], 'Position'] = 1\n",
    "#         # print(\"hello\", df.index[i])\n",
    "#         holding_position = True\n",
    "        \n",
    "for i in range(1, len(df)):\n",
    "    if df.loc[df.index[i], 'Signal'] == 1 and not holding_position:\n",
    "        df.loc[df.index[i], 'Position'] = 1\n",
    "        holding_position = True\n",
    "    elif  df.loc[df.index[i], 'Signal'] == 0 and holding_position:\n",
    "        df.loc[df.index[i], 'Position'] = 0\n",
    "        holding_position = False\n",
    "\n",
    "\n",
    "# Forward fill the positions to simulate holding positions\n",
    "df['Position'] = df['Position'].replace(to_replace=0, method='ffill')\n",
    "\n",
    "# Calculate strategy returns\n",
    "# df['Strategy_Returns'] = df['Position'].shift(1) * df['Close'].pct_change()\n",
    "df_test_period = df.loc[X_test.index[0]:]\n",
    "\n",
    "# Calculate strategy returns\n",
    "df_test_period['Strategy_Returns'] = df_test_period['Position'].shift(1) * df_test_period['Close'].pct_change()\n",
    "\n",
    "\n",
    "# Drop NaN values from returns\n",
    "# df.dropna(subset=['Strategy_Returns'], inplace=True)\n",
    "df_test_period.dropna(subset=['Strategy_Returns'], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(start_idx, len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[df.index > X_test.index[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[df2['VIX'] > 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(order_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_period.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Calculate cumulative returns\n",
    "# df['Cumulative_Strategy_Returns'] = (1 + df['Strategy_Returns']).cumprod()\n",
    "\n",
    "# # Plot cumulative returns\n",
    "# plt.figure(figsize=(14, 7))\n",
    "# plt.plot(df.index, df['Cumulative_Strategy_Returns'], label='Strategy Returns')\n",
    "# plt.title('Cumulative Strategy Returns')\n",
    "# plt.xlabel('Date')\n",
    "# plt.ylabel('Cumulative Returns')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "# # Calculate performance metrics\n",
    "# import numpy as np\n",
    "\n",
    "# # Calculate annualized return\n",
    "# annualized_return = df['Strategy_Returns'].mean() * 252\n",
    "\n",
    "# # Calculate annualized volatility\n",
    "# annualized_volatility = df['Strategy_Returns'].std() * np.sqrt(252)\n",
    "\n",
    "# # Calculate Sharpe ratio\n",
    "# risk_free_rate = 0.01  # Assuming a risk-free rate of 1%\n",
    "# sharpe_ratio = (annualized_return - risk_free_rate) / annualized_volatility\n",
    "\n",
    "# # Calculate maximum drawdown\n",
    "# cumulative_returns = (1 + df['Strategy_Returns']).cumprod()\n",
    "# running_max = cumulative_returns.cummax()\n",
    "# drawdown = (cumulative_returns - running_max) / running_max\n",
    "# max_drawdown = drawdown.min()\n",
    "\n",
    "# # Print performance metrics\n",
    "# print(f\"Annualized Return: {annualized_return:.2%}\")\n",
    "# print(f\"Annualized Volatility: {annualized_volatility:.2%}\")\n",
    "# print(f\"Sharpe Ratio: {sharpe_ratio:.2f}\")\n",
    "# print(f\"Maximum Drawdown: {max_drawdown:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate performance metrics\n",
    "# returns = df['Strategy_Returns']\n",
    "returns = df_test_period['Strategy_Returns']\n",
    "cumulative_returns = (1 + returns).cumprod() - 1\n",
    "perf_stats = {\n",
    "    'Annual Return': ep.annual_return(returns),\n",
    "    'Cumulative Returns': ep.cum_returns_final(returns),\n",
    "    'Annual Volatility': ep.annual_volatility(returns),\n",
    "    'Sharpe Ratio': ep.sharpe_ratio(returns),\n",
    "    'Sortino Ratio': ep.sortino_ratio(returns),\n",
    "    'Max Drawdown': ep.max_drawdown(returns),\n",
    "    'Calmar Ratio': ep.calmar_ratio(returns)\n",
    "}\n",
    "\n",
    "# Print performance metrics\n",
    "for metric, value in perf_stats.items():\n",
    "    print(f\"{metric}: {value:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cumulative returns\n",
    "cumulative_returns = ep.cum_returns(returns, starting_value=1.00)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(cumulative_returns, label='Strategy Returns')\n",
    "plt.title('Cumulative Returns')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate rolling Sharpe ratio\n",
    "def rolling_sharpe_ratio(returns, window=252):\n",
    "    return returns.rolling(window=window).mean() / returns.rolling(window=window).std()\n",
    "\n",
    "# Calculate the rolling Sharpe ratio\n",
    "rolling_sharpe = rolling_sharpe_ratio(returns)\n",
    "\n",
    "# Plot the rolling Sharpe ratio\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(rolling_sharpe, label='Rolling Sharpe Ratio')\n",
    "plt.title('Rolling Sharpe Ratio')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Sharpe Ratio')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Print the mean of the rolling Sharpe ratio\n",
    "print('Mean of Rolling Sharpe Ratio:', rolling_sharpe.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate drawdown\n",
    "def calculate_drawdown(returns):\n",
    "    cum_returns = (1 + returns).cumprod()\n",
    "    peak = cum_returns.cummax()\n",
    "    drawdown = (cum_returns - peak) / peak\n",
    "    return drawdown\n",
    "\n",
    "drawdown = calculate_drawdown(returns)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(drawdown, label='Drawdown')\n",
    "plt.title('Drawdown')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(drawdown.mean())\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Maximum drawdown : \", drawdown.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[df.index[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"Backtested/df.csv\")\n",
    "# returns.to_csv(\"Backtested/returns.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
